---
title: llama.cpp
slug: /guides/providers/llama-cpp
---

## Overview

[Nitro](https://github.com/janhq/nitro) is an inference server on top of [llama.cpp](https://github.com/ggerganov/llama.cpp). It provides an OpenAI-compatible API, queue, & scaling.

Nitro is the default AI engine downloaded with Jan. There is no additional setup needed.